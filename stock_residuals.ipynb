{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rpjena/random_matrix/blob/main/stock_residuals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\n\n\nclass StockResiduals:\n    \"\"\"\n    Compute OLS residuals from regressing each stock's return series against\n    a market (or any single-factor) return series.\n\n    For each stock i the model is:\n        R_i(t) = alpha_i + beta_i * R_m(t) + epsilon_i(t)\n\n    NaN / null handling: each stock is regressed using only the rows where\n    *both* that stock and the market have non-null values.  Rows that were\n    NaN in the input remain NaN in the residuals output.  If a stock has\n    fewer than ``min_obs`` valid observations the regression is skipped and\n    its alpha, beta, R-squared are set to NaN.\n\n    Parameters\n    ----------\n    stocks : pd.DataFrame\n        (T x N) DataFrame of stock return series. Index is the time axis\n        (dates or integers), columns are stock identifiers.\n    market : pd.Series\n        (T,) Series of market returns aligned to the same index as `stocks`.\n    min_obs : int, optional\n        Minimum number of non-NaN observations required to run a regression\n        for a given stock.  Default is 30.\n\n    Attributes\n    ----------\n    residuals : pd.DataFrame\n        (T x N) residual returns, same index/columns as `stocks`.\n        Rows that were NaN in the input stay NaN.\n    betas : pd.Series\n        Beta coefficient for each stock (indexed by stock name).\n    alphas : pd.Series\n        Intercept for each stock.\n    r_squared : pd.Series\n        R-squared for each stock regression.\n    obs_count : pd.Series\n        Number of valid (non-NaN) observations used per stock.\n    \"\"\"\n\n    def __init__(self, stocks, market, min_obs=30):\n        if stocks.shape[0] != market.shape[0]:\n            raise ValueError(\n                f\"Length mismatch: stocks has {stocks.shape[0]} rows, \"\n                f\"market has {market.shape[0]} rows.\"\n            )\n\n        self.stocks = stocks\n        self.market = market\n        self.min_obs = min_obs\n\n        # Run the regression\n        self.alphas, self.betas, self.r_squared, self.residuals, self.obs_count = (\n            self._fit()\n        )\n\n    def _fit(self):\n        \"\"\"\n        Vectorised OLS with NaN awareness.\n\n        Strategy\n        --------\n        1.  Identify rows where the market is valid (``mkt_valid``).\n        2.  For stocks that have *no* NaNs on those rows, run a single\n            batched regression (fast path — covers the common case).\n        3.  For the remaining stocks, regress one-by-one using each stock's\n            own valid-row mask (slow path — only for stocks with NaNs).\n\n        Returns\n        -------\n        alphas    : pd.Series\n        betas     : pd.Series\n        r_squared : pd.Series\n        residuals : pd.DataFrame\n        obs_count : pd.Series\n        \"\"\"\n        Y_full = self.stocks.values.astype(float)       # (T, N)\n        x_full = self.market.values.astype(float)        # (T,)\n        T, N = Y_full.shape\n        cols = self.stocks.columns\n        idx  = self.stocks.index\n\n        # Output arrays — default to NaN\n        alphas_arr = np.full(N, np.nan)\n        betas_arr  = np.full(N, np.nan)\n        r2_arr     = np.full(N, np.nan)\n        resid      = np.full_like(Y_full, np.nan)\n        obs_arr    = np.zeros(N, dtype=int)\n\n        mkt_valid = ~np.isnan(x_full)                    # (T,)\n        stock_nan  = np.isnan(Y_full)                    # (T, N)\n\n        # ---- fast path: stocks with no NaNs where market is valid ----\n        has_nan = stock_nan[mkt_valid].any(axis=0)       # (N,) bool\n        fast_mask = ~has_nan                             # columns for batch OLS\n        n_fast = fast_mask.sum()\n\n        if n_fast > 0:\n            rows = mkt_valid\n            x = x_full[rows]\n            Y = Y_full[np.ix_(rows, fast_mask)]\n            t = rows.sum()\n            obs_arr[fast_mask] = t\n\n            if t >= self.min_obs:\n                X = np.column_stack([np.ones(t), x])\n                XtX_inv = np.linalg.inv(X.T @ X)\n                coeffs = XtX_inv @ (X.T @ Y)            # (2, n_fast)\n\n                alphas_arr[fast_mask] = coeffs[0]\n                betas_arr[fast_mask]  = coeffs[1]\n\n                Y_hat = X @ coeffs\n                res   = Y - Y_hat\n                ss_res = np.sum(res ** 2, axis=0)\n                ss_tot = np.sum((Y - Y.mean(axis=0)) ** 2, axis=0)\n                r2_arr[fast_mask] = np.where(ss_tot > 0, 1.0 - ss_res / ss_tot, np.nan)\n\n                # Place residuals back; rows where market was NaN stay NaN\n                resid[np.ix_(rows, fast_mask)] = res\n\n        # ---- slow path: per-stock regression for columns with NaNs ----\n        slow_cols = np.where(has_nan)[0]\n        for j in slow_cols:\n            valid = mkt_valid & ~stock_nan[:, j]\n            t = valid.sum()\n            obs_arr[j] = t\n            if t < self.min_obs:\n                continue\n\n            x = x_full[valid]\n            y = Y_full[valid, j]\n            X = np.column_stack([np.ones(t), x])\n            XtX_inv = np.linalg.inv(X.T @ X)\n            coeffs = XtX_inv @ (X.T @ y)                # (2,)\n\n            alphas_arr[j] = coeffs[0]\n            betas_arr[j]  = coeffs[1]\n\n            y_hat = X @ coeffs\n            res   = y - y_hat\n            ss_res = np.sum(res ** 2)\n            ss_tot = np.sum((y - y.mean()) ** 2)\n            r2_arr[j] = (1.0 - ss_res / ss_tot) if ss_tot > 0 else np.nan\n\n            resid[valid, j] = res\n\n        return (\n            pd.Series(alphas_arr, index=cols, name='alpha'),\n            pd.Series(betas_arr,  index=cols, name='beta'),\n            pd.Series(r2_arr,     index=cols, name='r_squared'),\n            pd.DataFrame(resid,   index=idx,  columns=cols),\n            pd.Series(obs_arr,    index=cols, name='obs_count'),\n        )\n\n    def summary(self):\n        \"\"\"\n        Return a compact DataFrame with alpha, beta, R-squared, and\n        observation count per stock.\n\n        Returns\n        -------\n        pd.DataFrame\n            (N x 4) summary table.\n        \"\"\"\n        return pd.DataFrame({\n            'alpha':     self.alphas,\n            'beta':      self.betas,\n            'r_squared': self.r_squared,\n            'obs_count': self.obs_count,\n        })"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Example usage with synthetic data (including NaNs)\n\nGenerate a panel of T = 2000, N = 5000 with known betas, sprinkle in NaNs,\nthen verify recovery."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(42)\n\nT = 2000\nN = 5000\n\n# True parameters\ntrue_betas  = np.random.uniform(0.5, 1.8, size=N)\ntrue_alphas = np.random.normal(0.0001, 0.0005, size=N)\n\n# Market returns\nmarket_returns = np.random.normal(0.0005, 0.01, size=T)\n\n# Stock returns: R_i = alpha_i + beta_i * R_m + noise\nnoise = np.random.normal(0, 0.02, size=(T, N))\nstock_returns = true_alphas + np.outer(market_returns, true_betas) + noise\n\ndates = pd.date_range('2017-01-01', periods=T, freq='B')\ntickers = [f'S{i:04d}' for i in range(N)]\n\nstocks_df = pd.DataFrame(stock_returns, index=dates, columns=tickers)\nmarket_sr = pd.Series(market_returns, index=dates, name='MKT')\n\n# --- Inject NaNs ---\n# ~5% random NaNs across the panel\nnan_mask = np.random.rand(T, N) < 0.05\nstocks_df[nan_mask] = np.nan\n\n# A few NaNs in the market too\nmarket_sr.iloc[10:15] = np.nan\n\n# One stock with almost all NaNs (below min_obs threshold)\nstocks_df['S0000'] = np.nan\n\nprint(f'stocks shape: {stocks_df.shape}')\nprint(f'market shape: {market_sr.shape}')\nprint(f'stock NaN %:  {stocks_df.isna().mean().mean() * 100:.1f}%')\nprint(f'market NaN count: {market_sr.isna().sum()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StockResiduals(stocks_df, market_sr)\n",
    "\n",
    "print('--- Summary (first 10 stocks) ---')\n",
    "print(model.summary().head(10))\n",
    "print()\n",
    "print('--- Residuals (first 5 rows x first 5 stocks) ---')\n",
    "print(model.residuals.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify beta recovery (only for stocks that had enough obs)\nvalid = model.obs_count >= 30\nbeta_error = model.betas[valid].values - true_betas[valid.values]\nprint(f'Stocks with enough obs: {valid.sum()} / {N}')\nprint(f'Beta estimation error  — mean: {beta_error.mean():.6f}, std: {beta_error.std():.4f}')\nprint(f'Mean R-squared: {model.r_squared[valid].mean():.4f}')\nprint(f'Residual DataFrame shape: {model.residuals.shape}')\nprint()\n# Show that NaN rows stay NaN in residuals\nprint(f'NaN count in residuals: {model.residuals.isna().sum().sum()}')\nprint(f'S0000 beta (all-NaN stock): {model.betas[\"S0000\"]}')\nprint(f'S0000 obs_count: {model.obs_count[\"S0000\"]}')"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## PnL Beta: cross-sectional sensitivity of residuals to portfolio PnL\n\n**Layout**:\n- `residuals`: (N x T) — rows are stocks, columns are dates\n- `pnl`: (T x T) — columns are dates (DatetimeIndex); for each date `r`, `pnl[r]` is a T-length PnL vector\n- `betas` output: (N x T) — for each date `r`, regress all N stock residual series against `pnl[r]`, then forward-fill NaNs along the time axis\n\nFor each date $r$ and stock $i$:\n\n$$\\varepsilon_i(s) = \\alpha_i^{(r)} + \\beta_i^{(r)} \\cdot \\text{PnL}^{(r)}(s) + u_i(s), \\qquad s = 1, \\ldots, T$$\n\nNaN positions are filled with the last valid beta for that stock (forward-fill along time).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class PnLBeta:\n    \"\"\"\n    For each date r, regress every stock's residual time series against the\n    PnL column for that date, producing an (N x T) matrix of betas.\n\n    Model (for date r, stock i):\n        residual_i(s) = alpha_i^(r) + beta_i^(r) * pnl^(r)(s) + u_i(s)\n        for s = 1 ... T  (using only non-NaN rows for both)\n\n    After computing raw betas, NaN entries are forward-filled along the\n    time axis so every stock carries its last valid beta forward.\n\n    Parameters\n    ----------\n    residuals : pd.DataFrame\n        (N x T) residual returns — rows are stocks, columns are dates.\n    pnl : pd.DataFrame\n        (T x T) portfolio PnL — columns are a DatetimeIndex matching the\n        columns of `residuals`.  For date r, ``pnl[r]`` is a T-length\n        PnL vector.\n    min_obs : int, optional\n        Minimum number of jointly non-NaN observations required to run\n        OLS for a given date column.  Default is 30.\n\n    Attributes\n    ----------\n    betas : pd.DataFrame\n        (N x T) betas, forward-filled along the time axis (axis=1).\n    betas_raw : pd.DataFrame\n        (N x T) betas before forward-fill (NaN where regression was\n        skipped or insufficient data).\n    r_squared : pd.DataFrame\n        (N x T) R-squared per stock per date (not forward-filled).\n    \"\"\"\n\n    def __init__(self, residuals, pnl, min_obs=30):\n        # columns of residuals (dates) must appear in pnl columns\n        common_dates = residuals.columns.intersection(pnl.columns)\n        if common_dates.empty:\n            raise ValueError(\"No common dates between residuals columns and pnl columns.\")\n\n        self.residuals = residuals\n        self.pnl = pnl\n        self.min_obs = min_obs\n        self._common_dates = common_dates\n\n        self.betas_raw, self.r_squared = self._fit()\n        # Forward-fill along time axis: each stock keeps its last valid beta\n        self.betas = self.betas_raw.ffill(axis=1)\n\n    def _fit(self):\n        \"\"\"\n        For each date r in common_dates, run a vectorised OLS of\n        residuals (N series of length T) on pnl[r] (length T).\n\n        Returns\n        -------\n        betas_raw : pd.DataFrame  (N x T)\n        r_squared : pd.DataFrame  (N x T)\n        \"\"\"\n        # residuals: (N x T_cols) → work with the underlying (N, T_cols) array\n        # but regressions run over the row-axis of pnl (T_rows).\n        # Each regression uses the T_rows observations where both the PnL\n        # column and each stock's residual row are non-NaN.\n\n        R = self.residuals                              # (N x T_cols) DataFrame\n        stock_names = R.index\n        date_cols   = R.columns                         # DatetimeIndex (T_cols)\n        N = len(stock_names)\n        T_cols = len(date_cols)\n\n        betas_arr = np.full((N, T_cols), np.nan)\n        r2_arr    = np.full((N, T_cols), np.nan)\n\n        # Residuals as (N x T_cols) numpy; we need each stock's full time\n        # series as a column vector for the regression, so transpose to\n        # (T_cols x N) — this is \"Y\" for each regression.\n        Y = R.values.astype(float).T                    # (T_cols, N)\n        Y_nan = np.isnan(Y)                             # (T_cols, N)\n\n        for c_idx, date_r in enumerate(date_cols):\n            if date_r not in self.pnl.columns:\n                continue\n\n            x = self.pnl[date_r].values.astype(float)   # (T_rows,)\n\n            # pnl rows and residuals columns may differ in length;\n            # use the shorter of the two\n            L = min(len(x), Y.shape[0])\n            x_slice = x[:L]\n            Y_slice = Y[:L, :]                           # (L, N)\n\n            x_valid = ~np.isnan(x_slice)                 # (L,)\n\n            # --- fast path: stocks with no NaN in the valid-x rows ---\n            y_nan_slice = np.isnan(Y_slice)\n            stock_has_nan = y_nan_slice[x_valid].any(axis=0)   # (N,)\n            fast = ~stock_has_nan\n            n_fast = fast.sum()\n\n            # rows usable by the fast-path stocks\n            rows_fast = x_valid\n            t_fast = rows_fast.sum()\n\n            if n_fast > 0 and t_fast >= self.min_obs:\n                xf = x_slice[rows_fast]\n                Yf = Y_slice[np.ix_(rows_fast, fast)]    # (t_fast, n_fast)\n                Xf = np.column_stack([np.ones(t_fast), xf])\n                XtX_inv = np.linalg.inv(Xf.T @ Xf)\n                coeffs = XtX_inv @ (Xf.T @ Yf)           # (2, n_fast)\n\n                betas_arr[fast, c_idx] = coeffs[1]\n\n                Yhat = Xf @ coeffs\n                res  = Yf - Yhat\n                ss_res = np.sum(res ** 2, axis=0)\n                ss_tot = np.sum((Yf - Yf.mean(axis=0)) ** 2, axis=0)\n                r2_arr[fast, c_idx] = np.where(\n                    ss_tot > 0, 1.0 - ss_res / ss_tot, np.nan\n                )\n\n            # --- slow path: stocks that have NaNs ---\n            slow_idxs = np.where(stock_has_nan)[0]\n            for j in slow_idxs:\n                valid = x_valid & ~y_nan_slice[:, j]\n                t = valid.sum()\n                if t < self.min_obs:\n                    continue\n\n                xj = x_slice[valid]\n                yj = Y_slice[valid, j]\n                Xj = np.column_stack([np.ones(t), xj])\n                XtX_inv = np.linalg.inv(Xj.T @ Xj)\n                coeffs = XtX_inv @ (Xj.T @ yj)\n\n                betas_arr[j, c_idx] = coeffs[1]\n\n                yhat = Xj @ coeffs\n                res  = yj - yhat\n                ss_res = np.sum(res ** 2)\n                ss_tot = np.sum((yj - yj.mean()) ** 2)\n                r2_arr[j, c_idx] = (\n                    (1.0 - ss_res / ss_tot) if ss_tot > 0 else np.nan\n                )\n\n        return (\n            pd.DataFrame(betas_arr, index=stock_names, columns=date_cols),\n            pd.DataFrame(r2_arr,    index=stock_names, columns=date_cols),\n        )\n\n    def summary_at(self, date):\n        \"\"\"\n        Return beta (forward-filled) and R-squared for every stock at\n        a single date.\n\n        Parameters\n        ----------\n        date : column label\n            A date present in the columns.\n\n        Returns\n        -------\n        pd.DataFrame  (N x 2)\n        \"\"\"\n        return pd.DataFrame({\n            'beta':      self.betas[date],\n            'r_squared': self.r_squared[date],\n        })",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example: PnL betas from transposed residuals\n\nTranspose the `StockResiduals` output to (N x T) and build a synthetic\n(T x T) PnL DataFrame with DatetimeIndex columns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Transpose residuals to (N x T): stocks as rows, dates as columns\nresiduals_NxT = model.residuals.T                        # (N x T)\nprint(f'residuals (N x T): {residuals_NxT.shape}')\n\n# Synthetic PnL (T x T): columns are the same DatetimeIndex as residuals\nnp.random.seed(99)\nT_dates = len(dates)\npnl_data = np.random.normal(0, 0.01, size=(T_dates, T_dates))\n\n# Inject ~3 % NaNs into PnL\npnl_nan_mask = np.random.rand(T_dates, T_dates) < 0.03\npnl_data[pnl_nan_mask] = np.nan\n\npnl_TxT = pd.DataFrame(pnl_data, index=dates, columns=dates)\nprint(f'PnL (T x T):       {pnl_TxT.shape}')\nprint(f'PnL NaN %:          {pnl_TxT.isna().mean().mean() * 100:.1f}%')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "pnl_model = PnLBeta(residuals_NxT, pnl_TxT, min_obs=30)\n\nprint(f'betas_raw shape (N x T): {pnl_model.betas_raw.shape}')\nprint(f'betas shape (N x T):     {pnl_model.betas.shape}')\nprint(f'R² shape (N x T):        {pnl_model.r_squared.shape}')\nprint()\nprint('--- Raw betas (first 5 stocks x last 5 dates) ---')\nprint(pnl_model.betas_raw.iloc[:5, -5:])\nprint()\nprint('--- Forward-filled betas (first 5 stocks x last 5 dates) ---')\nprint(pnl_model.betas.iloc[:5, -5:])\nprint()\nprint('--- R² (first 5 stocks x last 5 dates) ---')\nprint(pnl_model.r_squared.iloc[:5, -5:])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Snapshot at a specific date\nsnapshot_date = dates[-1]\nsnap = pnl_model.summary_at(snapshot_date)\nprint(f'--- Summary at {snapshot_date.date()} (first 10 stocks) ---')\nprint(snap.head(10))\nprint()\n# S0000 had all-NaN residuals — beta should be NaN even after ffill\nprint(f'S0000 beta (all-NaN stock): {pnl_model.betas.loc[\"S0000\"].iloc[-1]}')\nprint()\n# NaN stats\nraw_nan = pnl_model.betas_raw.isna().sum().sum()\nfilled_nan = pnl_model.betas.isna().sum().sum()\nprint(f'NaN count — raw betas: {raw_nan}, after ffill: {filled_nan}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}