{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rpjena/random_matrix/blob/main/stock_residuals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\n\n\nclass StockResiduals:\n    \"\"\"\n    Compute OLS residuals from regressing each stock's return series against\n    a market (or any single-factor) return series.\n\n    For each stock i the model is:\n        R_i(t) = alpha_i + beta_i * R_m(t) + epsilon_i(t)\n\n    NaN / null handling: each stock is regressed using only the rows where\n    *both* that stock and the market have non-null values.  Rows that were\n    NaN in the input remain NaN in the residuals output.  If a stock has\n    fewer than ``min_obs`` valid observations the regression is skipped and\n    its alpha, beta, R-squared are set to NaN.\n\n    Parameters\n    ----------\n    stocks : pd.DataFrame\n        (T x N) DataFrame of stock return series. Index is the time axis\n        (dates or integers), columns are stock identifiers.\n    market : pd.Series\n        (T,) Series of market returns aligned to the same index as `stocks`.\n    min_obs : int, optional\n        Minimum number of non-NaN observations required to run a regression\n        for a given stock.  Default is 30.\n\n    Attributes\n    ----------\n    residuals : pd.DataFrame\n        (T x N) residual returns, same index/columns as `stocks`.\n        Rows that were NaN in the input stay NaN.\n    betas : pd.Series\n        Beta coefficient for each stock (indexed by stock name).\n    alphas : pd.Series\n        Intercept for each stock.\n    r_squared : pd.Series\n        R-squared for each stock regression.\n    obs_count : pd.Series\n        Number of valid (non-NaN) observations used per stock.\n    \"\"\"\n\n    def __init__(self, stocks, market, min_obs=30):\n        if stocks.shape[0] != market.shape[0]:\n            raise ValueError(\n                f\"Length mismatch: stocks has {stocks.shape[0]} rows, \"\n                f\"market has {market.shape[0]} rows.\"\n            )\n\n        self.stocks = stocks\n        self.market = market\n        self.min_obs = min_obs\n\n        # Run the regression\n        self.alphas, self.betas, self.r_squared, self.residuals, self.obs_count = (\n            self._fit()\n        )\n\n    def _fit(self):\n        \"\"\"\n        Vectorised OLS with NaN awareness.\n\n        Strategy\n        --------\n        1.  Identify rows where the market is valid (``mkt_valid``).\n        2.  For stocks that have *no* NaNs on those rows, run a single\n            batched regression (fast path — covers the common case).\n        3.  For the remaining stocks, regress one-by-one using each stock's\n            own valid-row mask (slow path — only for stocks with NaNs).\n\n        Returns\n        -------\n        alphas    : pd.Series\n        betas     : pd.Series\n        r_squared : pd.Series\n        residuals : pd.DataFrame\n        obs_count : pd.Series\n        \"\"\"\n        Y_full = self.stocks.values.astype(float)       # (T, N)\n        x_full = self.market.values.astype(float)        # (T,)\n        T, N = Y_full.shape\n        cols = self.stocks.columns\n        idx  = self.stocks.index\n\n        # Output arrays — default to NaN\n        alphas_arr = np.full(N, np.nan)\n        betas_arr  = np.full(N, np.nan)\n        r2_arr     = np.full(N, np.nan)\n        resid      = np.full_like(Y_full, np.nan)\n        obs_arr    = np.zeros(N, dtype=int)\n\n        mkt_valid = ~np.isnan(x_full)                    # (T,)\n        stock_nan  = np.isnan(Y_full)                    # (T, N)\n\n        # ---- fast path: stocks with no NaNs where market is valid ----\n        has_nan = stock_nan[mkt_valid].any(axis=0)       # (N,) bool\n        fast_mask = ~has_nan                             # columns for batch OLS\n        n_fast = fast_mask.sum()\n\n        if n_fast > 0:\n            rows = mkt_valid\n            x = x_full[rows]\n            Y = Y_full[np.ix_(rows, fast_mask)]\n            t = rows.sum()\n            obs_arr[fast_mask] = t\n\n            if t >= self.min_obs:\n                X = np.column_stack([np.ones(t), x])\n                XtX_inv = np.linalg.inv(X.T @ X)\n                coeffs = XtX_inv @ (X.T @ Y)            # (2, n_fast)\n\n                alphas_arr[fast_mask] = coeffs[0]\n                betas_arr[fast_mask]  = coeffs[1]\n\n                Y_hat = X @ coeffs\n                res   = Y - Y_hat\n                ss_res = np.sum(res ** 2, axis=0)\n                ss_tot = np.sum((Y - Y.mean(axis=0)) ** 2, axis=0)\n                r2_arr[fast_mask] = np.where(ss_tot > 0, 1.0 - ss_res / ss_tot, np.nan)\n\n                # Place residuals back; rows where market was NaN stay NaN\n                resid[np.ix_(rows, fast_mask)] = res\n\n        # ---- slow path: per-stock regression for columns with NaNs ----\n        slow_cols = np.where(has_nan)[0]\n        for j in slow_cols:\n            valid = mkt_valid & ~stock_nan[:, j]\n            t = valid.sum()\n            obs_arr[j] = t\n            if t < self.min_obs:\n                continue\n\n            x = x_full[valid]\n            y = Y_full[valid, j]\n            X = np.column_stack([np.ones(t), x])\n            XtX_inv = np.linalg.inv(X.T @ X)\n            coeffs = XtX_inv @ (X.T @ y)                # (2,)\n\n            alphas_arr[j] = coeffs[0]\n            betas_arr[j]  = coeffs[1]\n\n            y_hat = X @ coeffs\n            res   = y - y_hat\n            ss_res = np.sum(res ** 2)\n            ss_tot = np.sum((y - y.mean()) ** 2)\n            r2_arr[j] = (1.0 - ss_res / ss_tot) if ss_tot > 0 else np.nan\n\n            resid[valid, j] = res\n\n        return (\n            pd.Series(alphas_arr, index=cols, name='alpha'),\n            pd.Series(betas_arr,  index=cols, name='beta'),\n            pd.Series(r2_arr,     index=cols, name='r_squared'),\n            pd.DataFrame(resid,   index=idx,  columns=cols),\n            pd.Series(obs_arr,    index=cols, name='obs_count'),\n        )\n\n    def summary(self):\n        \"\"\"\n        Return a compact DataFrame with alpha, beta, R-squared, and\n        observation count per stock.\n\n        Returns\n        -------\n        pd.DataFrame\n            (N x 4) summary table.\n        \"\"\"\n        return pd.DataFrame({\n            'alpha':     self.alphas,\n            'beta':      self.betas,\n            'r_squared': self.r_squared,\n            'obs_count': self.obs_count,\n        })"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Example usage with synthetic data (including NaNs)\n\nGenerate a panel of T = 2000, N = 5000 with known betas, sprinkle in NaNs,\nthen verify recovery."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(42)\n\nT = 2000\nN = 5000\n\n# True parameters\ntrue_betas  = np.random.uniform(0.5, 1.8, size=N)\ntrue_alphas = np.random.normal(0.0001, 0.0005, size=N)\n\n# Market returns\nmarket_returns = np.random.normal(0.0005, 0.01, size=T)\n\n# Stock returns: R_i = alpha_i + beta_i * R_m + noise\nnoise = np.random.normal(0, 0.02, size=(T, N))\nstock_returns = true_alphas + np.outer(market_returns, true_betas) + noise\n\ndates = pd.date_range('2017-01-01', periods=T, freq='B')\ntickers = [f'S{i:04d}' for i in range(N)]\n\nstocks_df = pd.DataFrame(stock_returns, index=dates, columns=tickers)\nmarket_sr = pd.Series(market_returns, index=dates, name='MKT')\n\n# --- Inject NaNs ---\n# ~5% random NaNs across the panel\nnan_mask = np.random.rand(T, N) < 0.05\nstocks_df[nan_mask] = np.nan\n\n# A few NaNs in the market too\nmarket_sr.iloc[10:15] = np.nan\n\n# One stock with almost all NaNs (below min_obs threshold)\nstocks_df['S0000'] = np.nan\n\nprint(f'stocks shape: {stocks_df.shape}')\nprint(f'market shape: {market_sr.shape}')\nprint(f'stock NaN %:  {stocks_df.isna().mean().mean() * 100:.1f}%')\nprint(f'market NaN count: {market_sr.isna().sum()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StockResiduals(stocks_df, market_sr)\n",
    "\n",
    "print('--- Summary (first 10 stocks) ---')\n",
    "print(model.summary().head(10))\n",
    "print()\n",
    "print('--- Residuals (first 5 rows x first 5 stocks) ---')\n",
    "print(model.residuals.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify beta recovery (only for stocks that had enough obs)\nvalid = model.obs_count >= 30\nbeta_error = model.betas[valid].values - true_betas[valid.values]\nprint(f'Stocks with enough obs: {valid.sum()} / {N}')\nprint(f'Beta estimation error  — mean: {beta_error.mean():.6f}, std: {beta_error.std():.4f}')\nprint(f'Mean R-squared: {model.r_squared[valid].mean():.4f}')\nprint(f'Residual DataFrame shape: {model.residuals.shape}')\nprint()\n# Show that NaN rows stay NaN in residuals\nprint(f'NaN count in residuals: {model.residuals.isna().sum().sum()}')\nprint(f'S0000 beta (all-NaN stock): {model.betas[\"S0000\"]}')\nprint(f'S0000 obs_count: {model.obs_count[\"S0000\"]}')"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## PnL Beta: time-varying sensitivity of residuals to portfolio PnL\n\nFor each stock $i$ and each date $t$, estimate:\n\n$$\\varepsilon_i(s) = \\alpha_i(t) + \\beta_i(t) \\cdot \\text{PnL}_i(s) + u_i(s), \\qquad s \\in [t - W + 1,\\; t]$$\n\nusing a rolling window of size $W$.  The output is a $(T \\times N)$ DataFrame of rolling betas.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class PnLBeta:\n    \"\"\"\n    Compute rolling OLS betas of stock residuals on portfolio PnL,\n    producing a time-varying beta per stock.\n\n    Model (per stock i, rolling window ending at t):\n        residual_i(s) = alpha_i(t) + beta_i(t) * pnl_i(s) + u_i(s)\n\n    Uses the identity  beta = Cov(resid, pnl) / Var(pnl)  computed via\n    pandas rolling, so the entire (T x N) panel is vectorised — no\n    per-stock loop.\n\n    Parameters\n    ----------\n    residuals : pd.DataFrame\n        (T x N) residual returns (e.g. from StockResiduals.residuals).\n    pnl : pd.DataFrame\n        (T x N) portfolio PnL per stock, same index and columns as\n        `residuals`.\n    window : int, optional\n        Rolling window size.  Default is 252 (~ 1 year of trading days).\n    min_periods : int or None, optional\n        Minimum number of non-NaN observations in a window to produce a\n        beta.  Default is None, which uses ``window // 2``.\n\n    Attributes\n    ----------\n    betas : pd.DataFrame\n        (T x N) rolling betas.  The first ``window - 1`` rows (or rows\n        with fewer than ``min_periods`` valid obs) are NaN.\n    r_squared : pd.DataFrame\n        (T x N) rolling R-squared for each stock at each date.\n    \"\"\"\n\n    def __init__(self, residuals, pnl, window=252, min_periods=None):\n        if residuals.shape != pnl.shape:\n            raise ValueError(\n                f\"Shape mismatch: residuals {residuals.shape} vs pnl {pnl.shape}\"\n            )\n\n        self.residuals = residuals\n        self.pnl = pnl\n        self.window = window\n        self.min_periods = min_periods if min_periods is not None else window // 2\n\n        self.betas, self.r_squared = self._fit()\n\n    def _fit(self):\n        \"\"\"\n        Vectorised rolling OLS using rolling covariance / variance.\n\n        Returns\n        -------\n        betas     : pd.DataFrame  (T x N)\n        r_squared : pd.DataFrame  (T x N)\n        \"\"\"\n        w  = self.window\n        mp = self.min_periods\n\n        resid = self.residuals\n        pnl   = self.pnl\n\n        # Rolling moments — pandas broadcasts across all N columns at once\n        roll_cov = resid.rolling(w, min_periods=mp).cov(pnl)     # (T, N)\n        roll_var = pnl.rolling(w, min_periods=mp).var()           # (T, N)\n\n        betas = roll_cov / roll_var                               # (T, N)\n\n        # Rolling means for alpha and R²\n        resid_mean = resid.rolling(w, min_periods=mp).mean()\n        pnl_mean   = pnl.rolling(w, min_periods=mp).mean()\n        alphas     = resid_mean - betas * pnl_mean\n\n        # Fitted values & R²  (rolling)\n        fitted = alphas + betas * pnl\n        ss_res = ((resid - fitted) ** 2).rolling(w, min_periods=mp).sum()\n        resid_var = resid.rolling(w, min_periods=mp).var()\n        # count valid obs per window for ss_tot\n        count = resid.rolling(w, min_periods=mp).count()\n        ss_tot = resid_var * (count - 1)\n\n        r_squared = 1.0 - ss_res / ss_tot\n        # Clamp numerical noise — R² should be in [0, 1]\n        r_squared = r_squared.clip(lower=0.0, upper=1.0)\n\n        return betas, r_squared\n\n    def summary_at(self, date):\n        \"\"\"\n        Return beta and R-squared for every stock at a single date.\n\n        Parameters\n        ----------\n        date : index label\n            A value present in the DataFrame index.\n\n        Returns\n        -------\n        pd.DataFrame  (N x 2)\n        \"\"\"\n        return pd.DataFrame({\n            'beta':      self.betas.loc[date],\n            'r_squared': self.r_squared.loc[date],\n        })",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example: rolling PnL betas from the residuals computed above\n\nWe simulate a synthetic PnL DataFrame (same shape as residuals) with a\nknown linear relationship plus noise, then verify recovery.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Synthetic PnL: residual_i ≈ true_pnl_beta_i * pnl_i + noise\nnp.random.seed(99)\ntrue_pnl_betas = np.random.uniform(0.3, 1.5, size=N)\npnl_raw = np.random.normal(0, 0.01, size=(T, N))\n\n# Build PnL so that residual ≈ true_pnl_beta * pnl  (plus extra noise)\n# We use the original residuals (before NaN injection) for a clean signal\nresid_clean = true_alphas + np.outer(market_returns, true_betas) + noise\nresid_clean -= resid_clean.mean(axis=0)\n\npnl_data = (resid_clean - np.random.normal(0, 0.015, size=(T, N))) / true_pnl_betas\npnl_df = pd.DataFrame(pnl_data, index=dates, columns=tickers)\n\n# Propagate same NaN pattern so shapes align\npnl_df[nan_mask] = np.nan\npnl_df['S0000'] = np.nan\n\nprint(f'PnL shape: {pnl_df.shape}')\nprint(f'PnL NaN %: {pnl_df.isna().mean().mean() * 100:.1f}%')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "pnl_model = PnLBeta(model.residuals, pnl_df, window=252)\n\nprint(f'Rolling betas shape: {pnl_model.betas.shape}')\nprint(f'Rolling R² shape:    {pnl_model.r_squared.shape}')\nprint()\nprint('--- Rolling betas (last 5 rows x first 5 stocks) ---')\nprint(pnl_model.betas.iloc[-5:, :5])\nprint()\nprint('--- Rolling R² (last 5 rows x first 5 stocks) ---')\nprint(pnl_model.r_squared.iloc[-5:, :5])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Snapshot at a specific date\nsnapshot_date = dates[-1]\nsnap = pnl_model.summary_at(snapshot_date)\nprint(f'--- Summary at {snapshot_date.date()} (first 10 stocks) ---')\nprint(snap.head(10))\nprint()\nprint(f'S0000 beta (all-NaN stock): {pnl_model.betas[\"S0000\"].iloc[-1]}')\nprint(f'Mean rolling beta at last date: {pnl_model.betas.iloc[-1].mean():.4f}')\nprint(f'Mean rolling R² at last date:   {pnl_model.r_squared.iloc[-1].mean():.4f}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}