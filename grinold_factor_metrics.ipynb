{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rpjena/random_matrix/blob/main/grinold_factor_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grinold Factor Model Metrics\n",
    "\n",
    "Implementation of factor model evaluation metrics from the **Grinold & Kahn** framework,\n",
    "as described in *A Practitioner's Guide to Factor Models* (CFA Institute, 1994) and\n",
    "*Active Portfolio Management* (Grinold & Kahn, 1999).\n",
    "\n",
    "## Factor Model Specification\n",
    "\n",
    "The cross-sectional factor model for asset returns:\n",
    "\n",
    "$$r_i = \\sum_{k=1}^{K} X_{ik} f_k + u_i$$\n",
    "\n",
    "where:\n",
    "- $r_i$ = excess return of asset $i$\n",
    "- $X_{ik}$ = exposure of asset $i$ to factor $k$ (z-scored characteristic)\n",
    "- $f_k$ = return to factor $k$ (estimated via cross-sectional regression)\n",
    "- $u_i$ = specific (idiosyncratic) return of asset $i$\n",
    "\n",
    "In matrix form: $\\mathbf{r} = \\mathbf{X} \\mathbf{f} + \\mathbf{u}$\n",
    "\n",
    "## Metrics Implemented\n",
    "\n",
    "1. **Factor Return Estimation** via WLS cross-sectional regression\n",
    "2. **Factor Return t-statistics** and cumulative returns\n",
    "3. **Information Coefficient (IC)** — rank correlation of exposures vs. forward returns\n",
    "4. **IC Information Ratio (ICIR)** — mean IC / std IC\n",
    "5. **Quantile Analysis** — mean returns by factor exposure quintile\n",
    "6. **Cross-Sectional R-squared** — goodness of fit per period\n",
    "7. **Bias Statistic** — realized vs. predicted risk ratio\n",
    "8. **Factor Covariance Matrix** and correlation structure\n",
    "9. **Specific Risk Analysis** — residual diagnostics\n",
    "10. **Portfolio Risk Decomposition** — factor vs. specific risk\n",
    "11. **Factor Exposure Turnover** — stability of exposures over time\n",
    "12. **Variance Inflation Factor (VIF)** — multicollinearity diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation\n",
    "\n",
    "We generate a realistic panel of asset returns driven by a known factor structure.\n",
    "This allows us to validate our metrics against ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_factor_model_data(N=200, T=120, K=5, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic cross-sectional factor model data.\n",
    "\n",
    "    The data follows r_{i,t} = X_{i,t} f_t + u_{i,t} where factor exposures\n",
    "    evolve slowly over time (AR(1) with high persistence) and specific returns\n",
    "    have heterogeneous volatility.\n",
    "\n",
    "    Parameters:\n",
    "        N (int): Number of assets.\n",
    "        T (int): Number of time periods (months).\n",
    "        K (int): Number of factors.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        returns (np.array): Asset returns, shape (T, N).\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        true_factor_returns (np.array): True factor returns, shape (T, K).\n",
    "        specific_returns (np.array): Specific returns, shape (T, N).\n",
    "        market_cap (np.array): Market capitalizations, shape (N,).\n",
    "        factor_names (list): Names of the K factors.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    factor_names = ['Market', 'Size', 'Value', 'Momentum', 'Volatility'][:K]\n",
    "\n",
    "    # Market capitalizations (log-normal, for WLS weights)\n",
    "    log_mcap = rng.normal(loc=8.0, scale=1.5, size=N)  # log market cap\n",
    "    market_cap = np.exp(log_mcap)\n",
    "\n",
    "    # Factor exposures: AR(1) process with persistence rho=0.95\n",
    "    rho = 0.95\n",
    "    exposures = np.zeros((T, N, K))\n",
    "    exposures[0] = rng.randn(N, K)\n",
    "    for t in range(1, T):\n",
    "        exposures[t] = rho * exposures[t - 1] + np.sqrt(1 - rho**2) * rng.randn(N, K)\n",
    "\n",
    "    # Z-score exposures cross-sectionally each period\n",
    "    for t in range(T):\n",
    "        mu = exposures[t].mean(axis=0)\n",
    "        sigma = exposures[t].std(axis=0)\n",
    "        exposures[t] = (exposures[t] - mu) / sigma\n",
    "\n",
    "    # True factor returns: mean-reverting with realistic magnitudes\n",
    "    # Annualized: Market~6%, Size~2%, Value~3%, Momentum~4%, Vol~-1%\n",
    "    monthly_means = np.array([0.005, 0.0017, 0.0025, 0.0033, -0.0008])[:K]\n",
    "    monthly_stds = np.array([0.02, 0.012, 0.015, 0.018, 0.01])[:K]\n",
    "    true_factor_returns = np.zeros((T, K))\n",
    "    for k in range(K):\n",
    "        true_factor_returns[:, k] = rng.normal(monthly_means[k], monthly_stds[k], T)\n",
    "\n",
    "    # Specific returns: heterogeneous volatility (smaller for large-cap)\n",
    "    specific_vol = 0.08 / np.sqrt(market_cap / np.median(market_cap))  # monthly\n",
    "    specific_returns = np.zeros((T, N))\n",
    "    for t in range(T):\n",
    "        specific_returns[t] = rng.normal(0, specific_vol)\n",
    "\n",
    "    # Asset returns: r = X f + u\n",
    "    returns = np.zeros((T, N))\n",
    "    for t in range(T):\n",
    "        returns[t] = exposures[t] @ true_factor_returns[t] + specific_returns[t]\n",
    "\n",
    "    return returns, exposures, true_factor_returns, specific_returns, market_cap, factor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, K = 200, 120, 5\n",
    "returns, exposures, true_fret, specific_ret, market_cap, factor_names = \\\n",
    "    generate_factor_model_data(N, T, K)\n",
    "\n",
    "print(f'Assets: {N}, Periods: {T}, Factors: {K}')\n",
    "print(f'Factor names: {factor_names}')\n",
    "print(f'Returns shape: {returns.shape}')\n",
    "print(f'Exposures shape: {exposures.shape}')\n",
    "print(f'Market cap range: [{market_cap.min():.0f}, {market_cap.max():.0f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-Sectional WLS Regression (Factor Return Estimation)\n",
    "\n",
    "Factor returns are estimated each period by regressing the cross-section of asset returns\n",
    "on factor exposures using Weighted Least Squares (WLS):\n",
    "\n",
    "$$\\hat{\\mathbf{f}}_t = (\\mathbf{X}_t^\\top \\mathbf{W}_t \\mathbf{X}_t)^{-1} \\mathbf{X}_t^\\top \\mathbf{W}_t \\mathbf{r}_t$$\n",
    "\n",
    "where $\\mathbf{W}_t = \\text{diag}(\\sqrt{\\text{mcap}})$ following the BARRA convention\n",
    "that idiosyncratic risk decreases with market capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_factor_returns_wls(returns, exposures, market_cap):\n",
    "    \"\"\"\n",
    "    Estimate factor returns via WLS cross-sectional regression each period.\n",
    "\n",
    "    Parameters:\n",
    "        returns (np.array): Asset returns, shape (T, N).\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        market_cap (np.array): Market capitalizations, shape (N,).\n",
    "\n",
    "    Returns:\n",
    "        factor_returns (np.array): Estimated factor returns, shape (T, K).\n",
    "        residuals (np.array): Specific returns (residuals), shape (T, N).\n",
    "        r_squared (np.array): Cross-sectional R-squared, shape (T,).\n",
    "    \"\"\"\n",
    "    T, N, K = exposures.shape\n",
    "    w = np.sqrt(market_cap)  # WLS weights\n",
    "    W = np.diag(w)\n",
    "\n",
    "    factor_returns = np.zeros((T, K))\n",
    "    residuals = np.zeros((T, N))\n",
    "    r_squared = np.zeros(T)\n",
    "\n",
    "    for t in range(T):\n",
    "        X_t = exposures[t]  # (N, K)\n",
    "        r_t = returns[t]    # (N,)\n",
    "\n",
    "        # WLS: f = (X'WX)^{-1} X'Wr\n",
    "        XtW = X_t.T @ W  # (K, N)\n",
    "        factor_returns[t] = np.linalg.solve(XtW @ X_t, XtW @ r_t)\n",
    "\n",
    "        # Residuals\n",
    "        r_hat = X_t @ factor_returns[t]\n",
    "        residuals[t] = r_t - r_hat\n",
    "\n",
    "        # Weighted R-squared\n",
    "        r_bar = np.average(r_t, weights=w)\n",
    "        ss_tot = np.sum(w * (r_t - r_bar)**2)\n",
    "        ss_res = np.sum(w * residuals[t]**2)\n",
    "        r_squared[t] = 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "\n",
    "    return factor_returns, residuals, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_fret, residuals, r_squared = estimate_factor_returns_wls(returns, exposures, market_cap)\n",
    "\n",
    "print('Estimated factor returns shape:', est_fret.shape)\n",
    "print('Residuals shape:', residuals.shape)\n",
    "print(f'Mean cross-sectional R-squared: {r_squared.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factor Return Analysis\n",
    "\n",
    "For each factor, we compute:\n",
    "- **Mean return** (annualized)\n",
    "- **Volatility** (annualized)\n",
    "- **t-statistic**: $t_k = \\frac{\\bar{f}_k}{\\text{se}(f_k)} = \\frac{\\bar{f}_k}{\\sigma_k / \\sqrt{T}}$\n",
    "- **Cumulative returns**: $\\prod_{t=1}^{T}(1 + f_{k,t}) - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_return_statistics(factor_returns, factor_names, periods_per_year=12):\n",
    "    \"\"\"\n",
    "    Compute summary statistics for estimated factor returns.\n",
    "\n",
    "    Parameters:\n",
    "        factor_returns (np.array): Estimated factor returns, shape (T, K).\n",
    "        factor_names (list): Factor names.\n",
    "        periods_per_year (int): Periods per year for annualization.\n",
    "\n",
    "    Returns:\n",
    "        stats_df (pd.DataFrame): Summary statistics per factor.\n",
    "    \"\"\"\n",
    "    T, K = factor_returns.shape\n",
    "    means = factor_returns.mean(axis=0)\n",
    "    stds = factor_returns.std(axis=0, ddof=1)\n",
    "    t_stats = means / (stds / np.sqrt(T))\n",
    "\n",
    "    ann_mean = means * periods_per_year\n",
    "    ann_vol = stds * np.sqrt(periods_per_year)\n",
    "    sharpe = ann_mean / ann_vol\n",
    "\n",
    "    pct_positive = (factor_returns > 0).mean(axis=0)\n",
    "\n",
    "    stats_df = pd.DataFrame({\n",
    "        'Ann. Mean (%)': ann_mean * 100,\n",
    "        'Ann. Vol (%)': ann_vol * 100,\n",
    "        'Sharpe': sharpe,\n",
    "        't-stat': t_stats,\n",
    "        '% Positive': pct_positive * 100\n",
    "    }, index=factor_names)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fret_stats = factor_return_statistics(est_fret, factor_names)\n",
    "print('Factor Return Statistics (Estimated):')\n",
    "print(fret_stats.round(3))\n",
    "print()\n",
    "\n",
    "fret_stats_true = factor_return_statistics(true_fret, factor_names)\n",
    "print('Factor Return Statistics (True):')\n",
    "print(fret_stats_true.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative factor returns: estimated vs. true\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k in range(K):\n",
    "    ax = axes[k]\n",
    "    cum_est = np.cumprod(1 + est_fret[:, k]) - 1\n",
    "    cum_true = np.cumprod(1 + true_fret[:, k]) - 1\n",
    "    ax.plot(cum_est, label='Estimated', linewidth=1.5)\n",
    "    ax.plot(cum_true, label='True', linewidth=1.5, linestyle='--')\n",
    "    ax.set_title(f'{factor_names[k]} (t={fret_stats.loc[factor_names[k], \"t-stat\"]:.2f})')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Cumulative Return')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.axhline(0, color='grey', linewidth=0.5)\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[-1].set_visible(False)\n",
    "fig.suptitle('Cumulative Factor Returns: Estimated vs. True', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Information Coefficient (IC)\n",
    "\n",
    "The **Information Coefficient** measures the predictive power of factor exposures.\n",
    "For each factor $k$ at time $t$:\n",
    "\n",
    "$$\\text{IC}_{k,t} = \\text{RankCorr}(X_{k,t}, r_{t+1})$$\n",
    "\n",
    "This is the Spearman rank correlation between factor exposures at time $t$\n",
    "and subsequent asset returns at $t+1$.\n",
    "\n",
    "The **IC Information Ratio** (ICIR) summarizes IC persistence:\n",
    "\n",
    "$$\\text{ICIR}_k = \\frac{\\overline{\\text{IC}}_k}{\\sigma(\\text{IC}_k)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_coefficient(returns, exposures, factor_names):\n",
    "    \"\"\"\n",
    "    Compute the Information Coefficient (IC) for each factor over time.\n",
    "\n",
    "    IC is the Spearman rank correlation between factor exposures at time t\n",
    "    and asset returns at time t+1.\n",
    "\n",
    "    Parameters:\n",
    "        returns (np.array): Asset returns, shape (T, N).\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        factor_names (list): Factor names.\n",
    "\n",
    "    Returns:\n",
    "        ic_df (pd.DataFrame): IC time series, shape (T-1, K).\n",
    "        ic_summary (pd.DataFrame): IC summary statistics per factor.\n",
    "    \"\"\"\n",
    "    T, N, K = exposures.shape\n",
    "    ic_values = np.zeros((T - 1, K))\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        for k in range(K):\n",
    "            corr, _ = spearmanr(exposures[t, :, k], returns[t + 1])\n",
    "            ic_values[t, k] = corr\n",
    "\n",
    "    ic_df = pd.DataFrame(ic_values, columns=factor_names)\n",
    "\n",
    "    # Summary statistics\n",
    "    ic_mean = ic_df.mean()\n",
    "    ic_std = ic_df.std()\n",
    "    icir = ic_mean / ic_std\n",
    "    ic_t = ic_mean / (ic_std / np.sqrt(len(ic_df)))\n",
    "    pct_positive = (ic_df > 0).mean()\n",
    "\n",
    "    ic_summary = pd.DataFrame({\n",
    "        'Mean IC': ic_mean,\n",
    "        'Std IC': ic_std,\n",
    "        'ICIR': icir,\n",
    "        't-stat': ic_t,\n",
    "        '% Positive': pct_positive * 100\n",
    "    })\n",
    "\n",
    "    return ic_df, ic_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_df, ic_summary = compute_information_coefficient(returns, exposures, factor_names)\n",
    "\n",
    "print('IC Summary:')\n",
    "print(ic_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IC time series with rolling mean\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k in range(K):\n",
    "    ax = axes[k]\n",
    "    ax.bar(range(len(ic_df)), ic_df[factor_names[k]], alpha=0.4, width=1.0,\n",
    "           color='steelblue', label='IC')\n",
    "    rolling_ic = ic_df[factor_names[k]].rolling(12).mean()\n",
    "    ax.plot(rolling_ic, color='darkred', linewidth=2, label='12m rolling mean')\n",
    "    ax.axhline(0, color='black', linewidth=0.5)\n",
    "    ax.axhline(ic_summary.loc[factor_names[k], 'Mean IC'], color='green',\n",
    "               linewidth=1, linestyle='--', label=f'Mean={ic_summary.loc[factor_names[k], \"Mean IC\"]:.3f}')\n",
    "    ax.set_title(f'{factor_names[k]} IC (ICIR={ic_summary.loc[factor_names[k], \"ICIR\"]:.2f})')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "axes[-1].set_visible(False)\n",
    "fig.suptitle('Information Coefficient (IC) Time Series', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantile Analysis\n",
    "\n",
    "For each factor, assets are sorted into quintiles based on exposure, and the\n",
    "mean forward return of each quintile is computed. A monotonic relationship\n",
    "from Q1 to Q5 indicates predictive power.\n",
    "\n",
    "The **long-short spread** (Q5 - Q1) is the return from going long the\n",
    "top quintile and short the bottom quintile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_analysis(returns, exposures, factor_names, n_quantiles=5):\n",
    "    \"\"\"\n",
    "    Compute mean forward returns by factor exposure quantile.\n",
    "\n",
    "    Parameters:\n",
    "        returns (np.array): Asset returns, shape (T, N).\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        factor_names (list): Factor names.\n",
    "        n_quantiles (int): Number of quantile bins.\n",
    "\n",
    "    Returns:\n",
    "        quantile_returns (dict): {factor_name: DataFrame of mean returns per quantile per period}.\n",
    "        quantile_summary (pd.DataFrame): Annualized mean return per quantile per factor.\n",
    "    \"\"\"\n",
    "    T, N, K = exposures.shape\n",
    "    quantile_returns = {}\n",
    "\n",
    "    for k in range(K):\n",
    "        qr = np.zeros((T - 1, n_quantiles))\n",
    "        for t in range(T - 1):\n",
    "            # Assign quintiles based on exposure at time t\n",
    "            ranks = pd.Series(exposures[t, :, k]).rank(method='first')\n",
    "            quantile_labels = pd.qcut(ranks, n_quantiles, labels=False)\n",
    "\n",
    "            for q in range(n_quantiles):\n",
    "                mask = quantile_labels == q\n",
    "                qr[t, q] = returns[t + 1, mask].mean()\n",
    "\n",
    "        quantile_returns[factor_names[k]] = pd.DataFrame(\n",
    "            qr, columns=[f'Q{i+1}' for i in range(n_quantiles)])\n",
    "\n",
    "    # Summary: annualized mean returns per quantile\n",
    "    summary_data = {}\n",
    "    for k in range(K):\n",
    "        name = factor_names[k]\n",
    "        mean_qr = quantile_returns[name].mean() * 12  # annualize\n",
    "        summary_data[name] = mean_qr\n",
    "\n",
    "    quantile_summary = pd.DataFrame(summary_data).T\n",
    "    quantile_summary['L/S Spread'] = quantile_summary['Q5'] - quantile_summary['Q1']\n",
    "\n",
    "    return quantile_returns, quantile_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_ret, quantile_summary = quantile_analysis(returns, exposures, factor_names)\n",
    "\n",
    "print('Quantile Returns (Annualized %):')\n",
    "print((quantile_summary * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile return bar charts\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k in range(K):\n",
    "    ax = axes[k]\n",
    "    name = factor_names[k]\n",
    "    mean_qr = quantile_ret[name].mean() * 12 * 100  # annualized %\n",
    "    colors = ['#d73027', '#fc8d59', '#fee08b', '#91cf60', '#1a9850']\n",
    "    ax.bar(mean_qr.index, mean_qr.values, color=colors)\n",
    "    ax.set_title(f'{name} (Spread={quantile_summary.loc[name, \"L/S Spread\"]*100:.1f}%)')\n",
    "    ax.set_ylabel('Ann. Return (%)')\n",
    "    ax.axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "axes[-1].set_visible(False)\n",
    "fig.suptitle('Mean Quantile Returns by Factor Exposure', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Sectional R-squared\n",
    "\n",
    "The cross-sectional $R^2_t$ measures how much of the cross-sectional variation\n",
    "in returns the factor model explains at each time $t$:\n",
    "\n",
    "$$R^2_t = 1 - \\frac{\\sum_i w_i (r_{i,t} - \\hat{r}_{i,t})^2}{\\sum_i w_i (r_{i,t} - \\bar{r}_t)^2}$$\n",
    "\n",
    "A high-quality factor structure should explain a substantial fraction of\n",
    "cross-sectional return dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(r_squared, color='steelblue', linewidth=1, alpha=0.7)\n",
    "rolling_r2 = pd.Series(r_squared).rolling(12).mean()\n",
    "ax.plot(rolling_r2, color='darkred', linewidth=2, label='12m rolling mean')\n",
    "ax.axhline(r_squared.mean(), color='green', linestyle='--',\n",
    "           label=f'Mean={r_squared.mean():.3f}')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Cross-Sectional R-squared')\n",
    "ax.set_title('Cross-Sectional R-squared Over Time')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'R-squared: mean={r_squared.mean():.4f}, '\n",
    "      f'median={np.median(r_squared):.4f}, '\n",
    "      f'min={r_squared.min():.4f}, max={r_squared.max():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bias Statistic\n",
    "\n",
    "The **bias statistic** tests whether the risk model's forecasts are well-calibrated.\n",
    "For a portfolio $p$ with predicted volatility $\\sigma_p$, the standardized return is:\n",
    "\n",
    "$$z_{p,t} = \\frac{r_{p,t}}{\\sigma_{p,t}}$$\n",
    "\n",
    "The bias statistic is:\n",
    "\n",
    "$$B_p = \\text{std}(z_{p,t})$$\n",
    "\n",
    "- $B_p \\approx 1.0$: risk forecast is well-calibrated (unbiased)\n",
    "- $B_p > 1.0$: risk is under-predicted\n",
    "- $B_p < 1.0$: risk is over-predicted\n",
    "\n",
    "We compute bias statistics for each factor portfolio (unit exposure to one factor, zero to others)\n",
    "and for random portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_statistics(factor_returns, residuals, exposures, market_cap,\n",
    "                            factor_names, window=60):\n",
    "    \"\"\"\n",
    "    Compute bias statistics for factor portfolios and specific returns.\n",
    "\n",
    "    The bias statistic is the standard deviation of standardized returns\n",
    "    (realized return / predicted volatility). A value of 1.0 indicates\n",
    "    unbiased risk forecasts.\n",
    "\n",
    "    Parameters:\n",
    "        factor_returns (np.array): Estimated factor returns, shape (T, K).\n",
    "        residuals (np.array): Specific returns, shape (T, N).\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        market_cap (np.array): Market capitalizations, shape (N,).\n",
    "        factor_names (list): Factor names.\n",
    "        window (int): Rolling window for volatility estimation.\n",
    "\n",
    "    Returns:\n",
    "        bias_df (pd.DataFrame): Bias statistics per factor.\n",
    "        specific_bias (pd.DataFrame): Bias stats by specific risk decile.\n",
    "    \"\"\"\n",
    "    T, K = factor_returns.shape\n",
    "    N = residuals.shape[1]\n",
    "\n",
    "    # Factor bias statistics\n",
    "    bias_data = []\n",
    "    for k in range(K):\n",
    "        standardized = []\n",
    "        for t in range(window, T):\n",
    "            # Rolling predicted volatility\n",
    "            pred_vol = factor_returns[t-window:t, k].std(ddof=1)\n",
    "            if pred_vol > 1e-10:\n",
    "                standardized.append(factor_returns[t, k] / pred_vol)\n",
    "        bias_stat = np.std(standardized, ddof=1) if standardized else np.nan\n",
    "        bias_data.append({\n",
    "            'Factor': factor_names[k],\n",
    "            'Bias Statistic': bias_stat,\n",
    "            'Status': 'OK' if 0.75 < bias_stat < 1.25 else 'Warning'\n",
    "        })\n",
    "\n",
    "    bias_df = pd.DataFrame(bias_data).set_index('Factor')\n",
    "\n",
    "    # Specific return bias by volatility decile\n",
    "    spec_vol = residuals.std(axis=0, ddof=1)\n",
    "    decile_labels = pd.qcut(spec_vol, 10, labels=[f'D{i+1}' for i in range(10)])\n",
    "\n",
    "    decile_bias = []\n",
    "    for d in range(10):\n",
    "        label = f'D{d+1}'\n",
    "        mask = decile_labels == label\n",
    "        assets_in_decile = np.where(mask)[0]\n",
    "\n",
    "        standardized_all = []\n",
    "        for i in assets_in_decile:\n",
    "            for t in range(window, T):\n",
    "                pred_v = residuals[t-window:t, i].std(ddof=1)\n",
    "                if pred_v > 1e-10:\n",
    "                    standardized_all.append(residuals[t, i] / pred_v)\n",
    "\n",
    "        b = np.std(standardized_all, ddof=1) if standardized_all else np.nan\n",
    "        decile_bias.append({'Decile': label, 'Bias Statistic': b})\n",
    "\n",
    "    specific_bias = pd.DataFrame(decile_bias).set_index('Decile')\n",
    "\n",
    "    return bias_df, specific_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df, specific_bias = compute_bias_statistics(\n",
    "    est_fret, residuals, exposures, market_cap, factor_names, window=36)\n",
    "\n",
    "print('Factor Bias Statistics (target = 1.0):')\n",
    "print(bias_df.round(3))\n",
    "print()\n",
    "print('Specific Return Bias by Volatility Decile:')\n",
    "print(specific_bias.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Factor bias statistics\n",
    "colors = ['green' if s == 'OK' else 'orange' for s in bias_df['Status']]\n",
    "ax1.barh(bias_df.index, bias_df['Bias Statistic'], color=colors)\n",
    "ax1.axvline(1.0, color='red', linestyle='--', linewidth=1.5, label='Ideal = 1.0')\n",
    "ax1.axvline(0.75, color='grey', linestyle=':', linewidth=1)\n",
    "ax1.axvline(1.25, color='grey', linestyle=':', linewidth=1)\n",
    "ax1.set_xlabel('Bias Statistic')\n",
    "ax1.set_title('Factor Bias Statistics')\n",
    "ax1.legend()\n",
    "\n",
    "# Specific risk bias by decile\n",
    "ax2.bar(specific_bias.index, specific_bias['Bias Statistic'], color='steelblue')\n",
    "ax2.axhline(1.0, color='red', linestyle='--', linewidth=1.5, label='Ideal = 1.0')\n",
    "ax2.axhline(0.75, color='grey', linestyle=':', linewidth=1)\n",
    "ax2.axhline(1.25, color='grey', linestyle=':', linewidth=1)\n",
    "ax2.set_xlabel('Specific Vol Decile (Low to High)')\n",
    "ax2.set_ylabel('Bias Statistic')\n",
    "ax2.set_title('Specific Return Bias by Volatility Decile')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Factor Covariance Matrix\n",
    "\n",
    "The factor covariance matrix $\\Sigma_f$ is estimated from the time series of\n",
    "factor returns. This is a key input to portfolio risk:\n",
    "\n",
    "$$\\Sigma = \\mathbf{X} \\Sigma_f \\mathbf{X}^\\top + \\mathbf{D}$$\n",
    "\n",
    "where $\\mathbf{D}$ is the diagonal matrix of specific variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated factor covariance and correlation\n",
    "factor_cov = np.cov(est_fret, rowvar=False) * 12  # annualized\n",
    "factor_corr = np.corrcoef(est_fret, rowvar=False)\n",
    "\n",
    "# True factor covariance\n",
    "true_factor_cov = np.cov(true_fret, rowvar=False) * 12\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(pd.DataFrame(factor_corr, index=factor_names, columns=factor_names),\n",
    "            annot=True, fmt='.2f', cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "            ax=ax1)\n",
    "ax1.set_title('Estimated Factor Correlation')\n",
    "\n",
    "# Annualized factor volatilities: estimated vs true\n",
    "est_vol = np.sqrt(np.diag(factor_cov)) * 100\n",
    "true_vol = np.sqrt(np.diag(true_factor_cov)) * 100\n",
    "x = np.arange(K)\n",
    "width = 0.35\n",
    "ax2.bar(x - width/2, est_vol, width, label='Estimated', color='steelblue')\n",
    "ax2.bar(x + width/2, true_vol, width, label='True', color='coral')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(factor_names)\n",
    "ax2.set_ylabel('Annualized Volatility (%)')\n",
    "ax2.set_title('Factor Volatilities: Estimated vs True')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Specific Risk Analysis\n",
    "\n",
    "Specific (idiosyncratic) returns $u_{i,t}$ should be:\n",
    "- Approximately normally distributed\n",
    "- Uncorrelated across assets (the factor model captured all common variation)\n",
    "- Have volatility that decreases with market capitalization\n",
    "\n",
    "We check these properties with distributional diagnostics and\n",
    "cross-asset correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_risk_analysis(residuals, market_cap):\n",
    "    \"\"\"\n",
    "    Analyze properties of specific (idiosyncratic) returns.\n",
    "\n",
    "    Parameters:\n",
    "        residuals (np.array): Specific returns, shape (T, N).\n",
    "        market_cap (np.array): Market capitalizations, shape (N,).\n",
    "\n",
    "    Returns:\n",
    "        stats (dict): Distributional statistics.\n",
    "        spec_vol (np.array): Per-asset specific volatility, shape (N,).\n",
    "    \"\"\"\n",
    "    T, N = residuals.shape\n",
    "    spec_vol = residuals.std(axis=0, ddof=1) * np.sqrt(12)  # annualized\n",
    "\n",
    "    # Distributional stats of pooled residuals\n",
    "    pooled = residuals.flatten()\n",
    "    stats_dict = {\n",
    "        'Mean': pooled.mean(),\n",
    "        'Std': pooled.std(),\n",
    "        'Skewness': float(pd.Series(pooled).skew()),\n",
    "        'Kurtosis': float(pd.Series(pooled).kurtosis()),\n",
    "        'Mean Spec Vol (ann %)': spec_vol.mean() * 100,\n",
    "        'Median Spec Vol (ann %)': np.median(spec_vol) * 100\n",
    "    }\n",
    "\n",
    "    # Cross-asset correlation of residuals (should be near zero)\n",
    "    sample_pairs = min(500, N * (N - 1) // 2)\n",
    "    rng = np.random.RandomState(0)\n",
    "    pairwise_corrs = []\n",
    "    for _ in range(sample_pairs):\n",
    "        i, j = rng.choice(N, 2, replace=False)\n",
    "        c = np.corrcoef(residuals[:, i], residuals[:, j])[0, 1]\n",
    "        pairwise_corrs.append(c)\n",
    "    stats_dict['Mean Pairwise Corr'] = np.mean(pairwise_corrs)\n",
    "    stats_dict['Std Pairwise Corr'] = np.std(pairwise_corrs)\n",
    "\n",
    "    return stats_dict, spec_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_stats, spec_vol = specific_risk_analysis(residuals, market_cap)\n",
    "\n",
    "print('Specific Return Statistics:')\n",
    "for k, v in spec_stats.items():\n",
    "    print(f'  {k}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Distribution of pooled residuals\n",
    "ax = axes[0]\n",
    "pooled = residuals.flatten()\n",
    "ax.hist(pooled, bins=80, density=True, alpha=0.7, color='steelblue')\n",
    "x_grid = np.linspace(pooled.min(), pooled.max(), 200)\n",
    "ax.plot(x_grid, stats.norm.pdf(x_grid, pooled.mean(), pooled.std()),\n",
    "        'r-', linewidth=2, label='Normal fit')\n",
    "ax.set_title('Distribution of Specific Returns')\n",
    "ax.set_xlabel('Specific Return')\n",
    "ax.legend()\n",
    "\n",
    "# Specific vol vs log market cap\n",
    "ax = axes[1]\n",
    "ax.scatter(np.log(market_cap), spec_vol * 100, alpha=0.5, s=15, color='steelblue')\n",
    "z = np.polyfit(np.log(market_cap), spec_vol * 100, 1)\n",
    "p = np.poly1d(z)\n",
    "x_fit = np.linspace(np.log(market_cap).min(), np.log(market_cap).max(), 100)\n",
    "ax.plot(x_fit, p(x_fit), 'r-', linewidth=2)\n",
    "ax.set_xlabel('Log Market Cap')\n",
    "ax.set_ylabel('Annualized Specific Vol (%)')\n",
    "ax.set_title('Specific Risk vs. Market Cap')\n",
    "\n",
    "# Distribution of specific volatilities\n",
    "ax = axes[2]\n",
    "ax.hist(spec_vol * 100, bins=30, alpha=0.7, color='steelblue')\n",
    "ax.axvline(np.median(spec_vol) * 100, color='red', linestyle='--',\n",
    "           label=f'Median={np.median(spec_vol)*100:.1f}%')\n",
    "ax.set_xlabel('Annualized Specific Vol (%)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Specific Volatilities')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Portfolio Risk Decomposition\n",
    "\n",
    "For a portfolio with weight vector $\\mathbf{x}$, total risk decomposes as:\n",
    "\n",
    "$$\\sigma_p^2 = \\underbrace{\\mathbf{x}^\\top \\mathbf{X} \\Sigma_f \\mathbf{X}^\\top \\mathbf{x}}_{\\text{factor risk}} + \\underbrace{\\mathbf{x}^\\top \\mathbf{D} \\mathbf{x}}_{\\text{specific risk}}$$\n",
    "\n",
    "where $\\Sigma_f$ is the factor covariance matrix and $\\mathbf{D} = \\text{diag}(\\sigma^2_{u_i})$.\n",
    "\n",
    "This decomposition reveals what fraction of portfolio risk comes from\n",
    "factor exposures vs. idiosyncratic stock-specific risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_risk_decomposition(weights, exposures_t, factor_cov, specific_var,\n",
    "                                  factor_names):\n",
    "    \"\"\"\n",
    "    Decompose portfolio risk into factor and specific components.\n",
    "\n",
    "    Parameters:\n",
    "        weights (np.array): Portfolio weights, shape (N,).\n",
    "        exposures_t (np.array): Factor exposures at time t, shape (N, K).\n",
    "        factor_cov (np.array): Factor covariance matrix, shape (K, K).\n",
    "        specific_var (np.array): Specific variances, shape (N,).\n",
    "        factor_names (list): Factor names.\n",
    "\n",
    "    Returns:\n",
    "        decomp (dict): Risk decomposition results.\n",
    "    \"\"\"\n",
    "    # Portfolio factor exposures\n",
    "    port_exposures = exposures_t.T @ weights  # (K,)\n",
    "\n",
    "    # Factor risk\n",
    "    factor_var = port_exposures @ factor_cov @ port_exposures\n",
    "\n",
    "    # Specific risk\n",
    "    spec_var = weights @ (specific_var * weights)\n",
    "\n",
    "    # Total risk\n",
    "    total_var = factor_var + spec_var\n",
    "    total_vol = np.sqrt(total_var)\n",
    "\n",
    "    # Per-factor contribution\n",
    "    factor_mcr = factor_cov @ port_exposures  # marginal contribution\n",
    "    factor_contributions = port_exposures * factor_mcr\n",
    "\n",
    "    decomp = {\n",
    "        'Total Vol (ann %)': total_vol * 100,\n",
    "        'Factor Vol (ann %)': np.sqrt(factor_var) * 100,\n",
    "        'Specific Vol (ann %)': np.sqrt(spec_var) * 100,\n",
    "        'Factor Risk Share (%)': factor_var / total_var * 100,\n",
    "        'Specific Risk Share (%)': spec_var / total_var * 100,\n",
    "        'Portfolio Factor Exposures': pd.Series(port_exposures, index=factor_names),\n",
    "        'Factor Risk Contributions': pd.Series(\n",
    "            factor_contributions / total_var * 100, index=factor_names)\n",
    "    }\n",
    "\n",
    "    return decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example portfolios\n",
    "T_last = T - 1\n",
    "spec_var = residuals.var(axis=0, ddof=1)  # annualize below\n",
    "\n",
    "# Equal-weight portfolio\n",
    "w_eq = np.ones(N) / N\n",
    "\n",
    "# Cap-weight portfolio\n",
    "w_cap = market_cap / market_cap.sum()\n",
    "\n",
    "# Random active portfolio (long-short, sum to 0)\n",
    "rng = np.random.RandomState(123)\n",
    "w_active = rng.randn(N)\n",
    "w_active = w_active - w_active.mean()\n",
    "w_active = w_active / np.abs(w_active).sum() * 2  # gross exposure = 200%\n",
    "\n",
    "portfolios = {\n",
    "    'Equal-Weight': w_eq,\n",
    "    'Cap-Weight': w_cap,\n",
    "    'Long-Short Active': w_active\n",
    "}\n",
    "\n",
    "# Use monthly factor cov (not annualized) for consistent units\n",
    "factor_cov_monthly = np.cov(est_fret, rowvar=False)\n",
    "\n",
    "for name, w in portfolios.items():\n",
    "    decomp = portfolio_risk_decomposition(\n",
    "        w, exposures[T_last], factor_cov_monthly, spec_var, factor_names)\n",
    "    print(f'\\n--- {name} Portfolio ---')\n",
    "    print(f'  Total Vol (monthly):   {decomp[\"Total Vol (ann %)\"]:.2f}%')\n",
    "    print(f'  Factor Vol (monthly):  {decomp[\"Factor Vol (ann %)\"]:.2f}%')\n",
    "    print(f'  Specific Vol (monthly):{decomp[\"Specific Vol (ann %)\"]:.2f}%')\n",
    "    print(f'  Factor Risk Share:     {decomp[\"Factor Risk Share (%)\"]:.1f}%')\n",
    "    print(f'  Specific Risk Share:   {decomp[\"Specific Risk Share (%)\"]:.1f}%')\n",
    "    print(f'  Portfolio Exposures:')\n",
    "    print(f'    {decomp[\"Portfolio Factor Exposures\"].round(3).to_dict()}')\n",
    "    print(f'  Factor Risk Contributions (% of total variance):')\n",
    "    print(f'    {decomp[\"Factor Risk Contributions\"].round(2).to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Factor Exposure Turnover\n",
    "\n",
    "Factor exposure **turnover** measures how rapidly exposures change over time.\n",
    "High turnover implies a less stable factor definition. We measure turnover as\n",
    "the cross-sectional rank correlation of exposures between consecutive periods:\n",
    "\n",
    "$$\\text{Autocorr}_k = \\text{RankCorr}(X_{k,t}, X_{k,t-1})$$\n",
    "\n",
    "Values near 1.0 indicate stable, slowly-evolving exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_exposure_turnover(exposures, factor_names):\n",
    "    \"\"\"\n",
    "    Compute factor exposure turnover as rank autocorrelation.\n",
    "\n",
    "    Parameters:\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        factor_names (list): Factor names.\n",
    "\n",
    "    Returns:\n",
    "        turnover_df (pd.DataFrame): Rank autocorrelation per factor per period.\n",
    "        turnover_summary (pd.DataFrame): Summary statistics.\n",
    "    \"\"\"\n",
    "    T, N, K = exposures.shape\n",
    "    autocorr = np.zeros((T - 1, K))\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for k in range(K):\n",
    "            corr, _ = spearmanr(exposures[t, :, k], exposures[t - 1, :, k])\n",
    "            autocorr[t - 1, k] = corr\n",
    "\n",
    "    turnover_df = pd.DataFrame(autocorr, columns=factor_names)\n",
    "\n",
    "    turnover_summary = pd.DataFrame({\n",
    "        'Mean Rank Autocorr': turnover_df.mean(),\n",
    "        'Min Rank Autocorr': turnover_df.min(),\n",
    "        'Max Rank Autocorr': turnover_df.max()\n",
    "    })\n",
    "\n",
    "    return turnover_df, turnover_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_df, turnover_summary = factor_exposure_turnover(exposures, factor_names)\n",
    "\n",
    "print('Factor Exposure Turnover (Rank Autocorrelation):')\n",
    "print(turnover_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for k in range(K):\n",
    "    ax.plot(turnover_df[factor_names[k]], label=factor_names[k], linewidth=1, alpha=0.8)\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Rank Autocorrelation')\n",
    "ax.set_title('Factor Exposure Stability Over Time')\n",
    "ax.legend()\n",
    "ax.axhline(1.0, color='grey', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Variance Inflation Factor (VIF)\n",
    "\n",
    "The **VIF** measures multicollinearity among factor exposures. For factor $k$:\n",
    "\n",
    "$$\\text{VIF}_k = \\frac{1}{1 - R^2_k}$$\n",
    "\n",
    "where $R^2_k$ is the R-squared from regressing factor $k$'s exposures on all other factors.\n",
    "\n",
    "- VIF $\\leq$ 5: acceptable\n",
    "- VIF $>$ 10: severe multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vif(exposures, factor_names):\n",
    "    \"\"\"\n",
    "    Compute Variance Inflation Factors for factor exposures.\n",
    "\n",
    "    Parameters:\n",
    "        exposures (np.array): Factor exposures, shape (T, N, K).\n",
    "        factor_names (list): Factor names.\n",
    "\n",
    "    Returns:\n",
    "        vif_df (pd.DataFrame): VIF per factor, averaged and per-period.\n",
    "    \"\"\"\n",
    "    T, N, K = exposures.shape\n",
    "    vif_per_period = np.zeros((T, K))\n",
    "\n",
    "    for t in range(T):\n",
    "        X = exposures[t]  # (N, K)\n",
    "        for k in range(K):\n",
    "            y = X[:, k]\n",
    "            others = np.delete(X, k, axis=1)\n",
    "            # Add intercept\n",
    "            others_with_const = np.column_stack([np.ones(N), others])\n",
    "            # OLS: R-squared\n",
    "            beta = np.linalg.lstsq(others_with_const, y, rcond=None)[0]\n",
    "            y_hat = others_with_const @ beta\n",
    "            ss_res = np.sum((y - y_hat)**2)\n",
    "            ss_tot = np.sum((y - y.mean())**2)\n",
    "            r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "            vif_per_period[t, k] = 1.0 / (1.0 - r2) if r2 < 1.0 else np.inf\n",
    "\n",
    "    vif_mean = vif_per_period.mean(axis=0)\n",
    "    vif_max = vif_per_period.max(axis=0)\n",
    "\n",
    "    vif_df = pd.DataFrame({\n",
    "        'Mean VIF': vif_mean,\n",
    "        'Max VIF': vif_max,\n",
    "        'Status': ['OK' if v <= 5 else 'High' if v <= 10 else 'Severe'\n",
    "                    for v in vif_mean]\n",
    "    }, index=factor_names)\n",
    "\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = compute_vif(exposures, factor_names)\n",
    "\n",
    "print('Variance Inflation Factors (VIF):')\n",
    "print(vif_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary Dashboard\n",
    "\n",
    "Consolidated view of all factor model diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summary_dashboard(fret_stats, ic_summary, quantile_summary,\n",
    "                             bias_df, vif_df, turnover_summary, r_squared):\n",
    "    \"\"\"\n",
    "    Build a consolidated summary of all factor model metrics.\n",
    "\n",
    "    Parameters:\n",
    "        fret_stats (pd.DataFrame): Factor return statistics.\n",
    "        ic_summary (pd.DataFrame): IC summary.\n",
    "        quantile_summary (pd.DataFrame): Quantile return summary.\n",
    "        bias_df (pd.DataFrame): Bias statistics.\n",
    "        vif_df (pd.DataFrame): VIF statistics.\n",
    "        turnover_summary (pd.DataFrame): Turnover summary.\n",
    "        r_squared (np.array): Cross-sectional R-squared.\n",
    "\n",
    "    Returns:\n",
    "        dashboard (pd.DataFrame): Consolidated metrics.\n",
    "    \"\"\"\n",
    "    dashboard = pd.DataFrame(index=fret_stats.index)\n",
    "\n",
    "    # Factor returns\n",
    "    dashboard['Ann. Return (%)'] = fret_stats['Ann. Mean (%)']\n",
    "    dashboard['Ann. Vol (%)'] = fret_stats['Ann. Vol (%)']\n",
    "    dashboard['Ret t-stat'] = fret_stats['t-stat']\n",
    "\n",
    "    # IC\n",
    "    dashboard['Mean IC'] = ic_summary['Mean IC']\n",
    "    dashboard['ICIR'] = ic_summary['ICIR']\n",
    "\n",
    "    # Quantile spread\n",
    "    dashboard['L/S Spread (%)'] = quantile_summary['L/S Spread'] * 100\n",
    "\n",
    "    # Bias\n",
    "    dashboard['Bias Stat'] = bias_df['Bias Statistic']\n",
    "\n",
    "    # VIF\n",
    "    dashboard['VIF'] = vif_df['Mean VIF']\n",
    "\n",
    "    # Turnover\n",
    "    dashboard['Exp. Autocorr'] = turnover_summary['Mean Rank Autocorr']\n",
    "\n",
    "    return dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = build_summary_dashboard(\n",
    "    fret_stats, ic_summary, quantile_summary, bias_df, vif_df,\n",
    "    turnover_summary, r_squared)\n",
    "\n",
    "print('=' * 90)\n",
    "print('GRINOLD FACTOR MODEL METRICS — SUMMARY DASHBOARD')\n",
    "print('=' * 90)\n",
    "print(dashboard.round(3).to_string())\n",
    "print()\n",
    "print(f'Cross-Sectional R-squared: mean={r_squared.mean():.4f}, '\n",
    "      f'median={np.median(r_squared):.4f}')\n",
    "print('=' * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual summary: heatmap of key metrics (normalized for display)\n",
    "display_cols = ['Ret t-stat', 'ICIR', 'L/S Spread (%)', 'Bias Stat', 'VIF', 'Exp. Autocorr']\n",
    "display_df = dashboard[display_cols].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.heatmap(display_df, annot=True, fmt='.2f', cmap='RdYlGn', center=0, ax=ax)\n",
    "ax.set_title('Factor Model Metrics Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Grinold, R. C. & Kahn, R. N. (1994). \"Multiple-Factor Models for Portfolio Risk.\" In *A Practitioner's Guide to Factor Models*, CFA Institute Research Foundation.\n",
    "- Grinold, R. C. & Kahn, R. N. (1999). *Active Portfolio Management*. McGraw-Hill.\n",
    "- Menchero, J., Orr, D. J., & Wang, J. (2011). \"The Barra US Equity Model (USE4).\" MSCI Methodology Notes.\n",
    "- Fama, E. F. & MacBeth, J. D. (1973). \"Risk, Return, and Equilibrium: Empirical Tests.\" *Journal of Political Economy*."
   ]
  }
 ]
}
